# -*- coding: utf-8 -*-
"""MNISTlargeUntrainedNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mHj5DWUljzXdovIxYueZtZROLkq4vWN8

# MNIST Large Untrained Net

Derived from https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb
"""

import tensorflow as tf
print("TensorFlow version:", tf.__version__)

"""## Load data"""

mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

"""## Define model"""

generateLargeNetworkUntrained = True
useSparsity = True
if(useSparsity):
    sparsityProbabilityOfConnection = 0.1 #1-sparsity
if(generateLargeNetworkUntrained):
        layerRatio = 100 #100
else:
        layerRatio = 1

def kernelInitializerWithSparsity(shape, dtype=None):
    initialisedWeights = tf.random.normal(shape, dtype=dtype) #change to glorot_uniform?
    sparsityMatrixMask = tf.random.uniform(shape, minval=0.0, maxval=1.0, dtype=tf.dtypes.float32)
    sparsityMatrixMask = tf.math.less(sparsityMatrixMask, sparsityProbabilityOfConnection)
    sparsityMatrixMask = tf.cast(sparsityMatrixMask, dtype=tf.dtypes.float32)
    initialisedWeights = tf.multiply(initialisedWeights, sparsityMatrixMask)
    return initialisedWeights
if(useSparsity):
    kernelInitializer = kernelInitializerWithSparsity
else:
    kernelInitializer = 'glorot_uniform'

if(generateLargeNetworkUntrained):
    #only train the last layer
    model = tf.keras.models.Sequential([
        tf.keras.layers.Flatten(input_shape=(28, 28)),
        tf.keras.layers.Dense(128*layerRatio, kernel_initializer=kernelInitializer, activation='relu'),
        tf.keras.layers.Dense(128*layerRatio, kernel_initializer=kernelInitializer, activation='relu'),
        #tf.keras.layers.Dense(128*largeNetworkRatio, kernel_initializer=kernelInitializer, activation='relu'),    
        tf.keras.layers.Lambda(lambda x: tf.keras.backend.stop_gradient(x)),
        tf.keras.layers.Dense(10)
    ])
    #evaluation accuracy: 0.9758 (with 1 or 2 hidden layers)
else:
    model = tf.keras.models.Sequential([
        tf.keras.layers.Flatten(input_shape=(28, 28)),
        tf.keras.layers.Dense(128*layerRatio, kernel_initializer=kernelInitializer, activation='relu'),
        tf.keras.layers.Dense(128*layerRatio, kernel_initializer=kernelInitializer, activation='relu'),
        tf.keras.layers.Dense(10)
    ])
    #evaluation accuracy: 0.9764

loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

model.compile(optimizer='adam',
              loss=loss_fn,
              metrics=['accuracy'])


print(model.summary())

"""## Train model"""

model.fit(x_train, y_train, epochs=5)



"""## Evaluate model"""

model.evaluate(x_test,  y_test, verbose=2)

probability_model = tf.keras.Sequential([
    model,
    tf.keras.layers.Softmax()
])

probability_model(x_test[:5])