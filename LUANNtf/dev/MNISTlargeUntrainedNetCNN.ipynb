{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fyMqv0I6N7V"
      },
      "source": [
        "Adapted from [Keras GitHub Example](http://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py) and [Yassine Ghouzam's NB](https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6)\n",
        "\n",
        "TensorFlow 1.x --> TensorFlow 2.x\n",
        "\n",
        "SciKit Learn --> TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqubie9M6N7a"
      },
      "source": [
        "# 1. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP-TbLBC6N7a"
      },
      "source": [
        "This tutorial is an introduction to Convolutional Neural Networks using TensorFlow 2.x Keras API. The dataset that we will work it is the MNIST dataset, a dataset of handwritten digits 0-9, and we will use a Sequential CNN to predict which digit was drawn.\n",
        "\n",
        "This model reaches 99.3% accuracy.\n",
        "\n",
        "To prepare our notebook, run the next cell to import the necessary packages and change the accelerator from ```None``` to ```GPU```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhS7EGDb6N7c",
        "outputId": "6caec647-f964-433f-9466-21f27cd129ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhJiq6jg6N7e"
      },
      "source": [
        "# 2. Data Preprocessing\n",
        "\n",
        "Before building any ML model, it is important to preprocess the data. In fact, data preprocessing will generally take up the most time in any ML pipeline. The following module goes over the steps to preprocess the MNIST dataset for our purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14FxXkn36N7f"
      },
      "source": [
        "## 2.1 Load Data\n",
        "\n",
        "Our first step is to load the data and divide it into a training and testing dataset. The MNIST dataset can be downloaded directly from TensorFlow and has already been divided. Run the next cell to import the data.\n",
        "\n",
        "``` x_train ``` is the dataset of 28x28 images of handwritten digits that the model will be trained on.\n",
        "\n",
        "```y_train``` is the dataset of labels that correspond to ```x_train```. \n",
        "\n",
        "``` x_test ``` is the dataset of 28x28 images of handwritten digits that the model will be tested on.\n",
        "\n",
        "```y_test``` is the dataset of labels that correspond to ```x_test```. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8efB13kY6N7g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9116bed-a45f-4323-a8cb-b0f8ddfe16f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip-IoQOH6N7g"
      },
      "source": [
        "Run the following code to see the counts of each digit present in our training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "lyuCUAZ_6N7h",
        "outputId": "8fa07245-d94c-4163-a8d3-a925c2cdc808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f73ba421890>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD6CAYAAABQ6WtbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVnElEQVR4nO3df7BfdX3n8edLIlWpNUHSLCZ0w6wZW9pdFe8Alq51zRoCtYZxkMFZNcuyE3cGHV07W7GdWSwsO7rb1qptmclINFiVRtSFOoyYwV/b7vLjBhGB6HJFkWSB3JqIP1i12Pf+8f1EvyT3ci5yz7k33Odj5jvfcz7nc87nfTOBV845n3NuqgpJkh7LUxa6AEnS4mdYSJI6GRaSpE6GhSSpk2EhSepkWEiSOvUWFkmel+S2sc93k7wlybFJdia5u32vaP2T5L1JppLcnuTksWNtbv3vTrK5r5olSTPLEM9ZJDkK2AucClwI7K+qdya5CFhRVW9LchbwJuCs1u89VXVqkmOBSWACKGAX8KKqOjDbeMcdd1ytXbu2159Jkp5sdu3a9fdVtXKmbcsGqmE98PWqujfJJuClrX078HngbcAm4MoapdeNSZYnOb713VlV+wGS7AQ2Ah+dbbC1a9cyOTnZ048iSU9OSe6dbdtQ9yzO42f/c19VVfe35QeAVW15NXDf2D57Wtts7ZKkgfQeFkmOBl4JfOzQbe0sYl6ugyXZkmQyyeT09PR8HFKS1AxxZnEmcGtVPdjWH2yXl2jf+1r7XuCEsf3WtLbZ2h+lqrZW1URVTaxcOeMlN0nSz2mIsHgNj76/cC1wcEbTZuCasfbXt1lRpwEPtctV1wMbkqxoM6c2tDZJ0kB6vcGd5Bjg5cAbxprfCexIcgFwL3Bua7+O0UyoKeBh4HyAqtqf5FLgltbvkoM3uyVJwxhk6uzQJiYmytlQkvT4JNlVVRMzbfMJbklSJ8NCktTJsJAkdRrqCe4l71uX/PPBxvqV//yVwcaStDR4ZiFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6uRbZyUtCu94xzuelGM9WXhmIUnqZFhIkjoZFpKkTt6z0OC+8JLfHmys3/7iFwYbS3oy6/XMIsnyJFcn+WqS3UlenOTYJDuT3N2+V7S+SfLeJFNJbk9y8thxNrf+dyfZ3GfNkqTD9X0Z6j3Ap6vqV4HnA7uBi4AbqmodcENbBzgTWNc+W4DLAZIcC1wMnAqcAlx8MGAkScPoLSySPAt4CXAFQFX9uKq+A2wCtrdu24Gz2/Im4MoauRFYnuR44AxgZ1Xtr6oDwE5gY191S5IO1+eZxYnANPCBJF9K8v4kxwCrqur+1ucBYFVbXg3cN7b/ntY2W7skaSB9hsUy4GTg8qp6IfADfnbJCYCqKqDmY7AkW5JMJpmcnp6ej0NKkpo+Z0PtAfZU1U1t/WpGYfFgkuOr6v52mWlf274XOGFs/zWtbS/w0kPaP3/oYFW1FdgKMDExMS8B9GR0+vtOH2Scv3vT3w0yjvRk9Pyrrx9srC+fc8ac+vUWFlX1QJL7kjyvqr4GrAfuap/NwDvb9zVtl2uBNya5itHN7IdaoFwP/Nexm9obgLc/nlpe9J+ufOI/0Bzs+u+vH2Qcab7tvuyzg4zza3/4skHG0fzr+zmLNwEfTnI0cA9wPqNLXzuSXADcC5zb+l4HnAVMAQ+3vlTV/iSXAre0fpdU1f6e65Ykjek1LKrqNmBihk3rZ+hbwIWzHGcbsG1+q9NS9+e/9zeDjPPGP/ndQcbR/NjxsVMGGefcV988yDjzxdd9SJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6tT3W2clPYbLXnvOYGP94V9dPdhYevLxzEKS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUqdewSPLNJF9JcluSydZ2bJKdSe5u3ytae5K8N8lUktuTnDx2nM2t/91JNvdZsyTpcEOcWfyrqnpBVU209YuAG6pqHXBDWwc4E1jXPluAy2EULsDFwKnAKcDFBwNGkjSMhbgMtQnY3pa3A2ePtV9ZIzcCy5McD5wB7Kyq/VV1ANgJbBy6aElayvoOiwI+k2RXki2tbVVV3d+WHwBWteXVwH1j++5pbbO1P0qSLUkmk0xOT0/P588gSUte32+d/a2q2pvkl4GdSb46vrGqKknNx0BVtRXYCjAxMTEvx5QkjfR6ZlFVe9v3PuCTjO45PNguL9G+97Xue4ETxnZf09pma5ckDaS3sEhyTJJnHlwGNgB3ANcCB2c0bQauacvXAq9vs6JOAx5ql6uuBzYkWdFubG9obZKkgfR5GWoV8MkkB8f5SFV9OsktwI4kFwD3Aue2/tcBZwFTwMPA+QBVtT/JpcAtrd8lVbW/x7olSYfoLSyq6h7g+TO0fxtYP0N7ARfOcqxtwLb5rlGSNDc+wS1J6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnq1HtYJDkqyZeSfKqtn5jkpiRTSf46ydGt/Rfa+lTbvnbsGG9v7V9LckbfNUuSHm2IM4s3A7vH1t8FvLuqngscAC5o7RcAB1r7u1s/kpwEnAf8OrAR+MskRw1QtySp6TUskqwBfgd4f1sP8DLg6tZlO3B2W97U1mnb17f+m4CrqupHVfUNYAo4pc+6JUmP1veZxZ8Bvw/8Y1t/NvCdqnqkre8BVrfl1cB9AG37Q63/T9tn2EeSNIDewiLJK4B9VbWrrzEOGW9Lkskkk9PT00MMKUlLRp9nFqcDr0zyTeAqRpef3gMsT7Ks9VkD7G3Le4ETANr2ZwHfHm+fYZ+fqqqtVTVRVRMrV66c/59Gkpaw3sKiqt5eVWuqai2jG9Sfrap/A3wOOKd12wxc05avbeu07Z+tqmrt57XZUicC64Cb+6pbknS4OYVFkhvm0jZHbwPemmSK0T2JK1r7FcCzW/tbgYsAqupOYAdwF/Bp4MKq+snPObYk6eew7LE2Jnka8AzguCQrgLRNv8TjuMlcVZ8HPt+W72GG2UxV9UPg1bPsfxlw2VzHkyTNr8cMC+ANwFuA5wC7+FlYfBf48x7rkiQtIo8ZFlX1HuA9Sd5UVe8bqCZJ0iLTdWYBQFW9L8lvAmvH96mqK3uqS5K0iMwpLJJ8CPhnwG3AwZvLBRgWkrQEzCksgAngpDaVVZK0xMz1OYs7gH/SZyGSpMVrrmcWxwF3JbkZ+NHBxqp6ZS9VSZIWlbmGxTv6LEKStLjNdTbUF/ouRJK0eM11NtT3GM1+AjgaeCrwg6r6pb4KkyQtHnM9s3jmweWxX0h0Wl9FSZIWl8f91tka+R+AvwtbkpaIuV6GetXY6lMYPXfxw14qkiQtOnOdDfW7Y8uPAN9kdClKkrQEzPWexfl9FyJJWrzm+suP1iT5ZJJ97fPxJGv6Lk6StDjM9Qb3Bxj9etPntM/ftDZJ0hIw17BYWVUfqKpH2ueDwMoe65IkLSJzDYtvJ3ltkqPa57XAt/ssTJK0eMw1LP4dcC7wAHA/cA7wb3uqSZK0yMx16uwlwOaqOgCQ5FjgjxmFiCTpSW6uZxb/4mBQAFTVfuCF/ZQkSVps5hoWT0my4uBKO7N4zLOSJE9LcnOSLye5M8kftfYTk9yUZCrJXyc5urX/QlufatvXjh3r7a39a0l8zYgkDWyuYfEnwP9OcmmSS4H/Bfy3jn1+BLysqp4PvADYmOQ04F3Au6vqucAB4ILW/wLgQGt/d+tHkpOA84BfBzYCf5nkqLn+gJKkJ25OYVFVVwKvAh5sn1dV1Yc69qmq+n5bfWr7FPAy4OrWvh04uy1vauu07evH3nB7VVX9qKq+AUwBp8ylbknS/JjrDW6q6i7grsdz8HYGsAt4LvAXwNeB71TVI63LHmB1W14N3NfGeiTJQ8CzW/uNY4cd30eSNIDH/Yryx6OqflJVLwDWMDob+NW+xkqyJclkksnp6em+hpGkJanXsDioqr4DfA54MbA8ycEzmjXA3ra8FzgBoG1/FqMH/37aPsM+42NsraqJqppYudKHyyVpPvUWFklWJlnelp8OvBzYzSg0zmndNgPXtOVr2zpt+2erqlr7eW221InAOuDmvuqWJB1uzvcsfg7HA9vbfYunADuq6lNJ7gKuSvJfgC8BV7T+VwAfSjIF7Gc0A4qqujPJDkb3Sx4BLqyqn/RYtyTpEL2FRVXdzgwP7lXVPcwwm6mqfgi8epZjXQZcNt81SpLmZpB7FpKkI5thIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSerUW1gkOSHJ55LcleTOJG9u7ccm2Znk7va9orUnyXuTTCW5PcnJY8fa3PrfnWRzXzVLkmbW55nFI8DvVdVJwGnAhUlOAi4CbqiqdcANbR3gTGBd+2wBLodRuAAXA6cCpwAXHwwYSdIweguLqrq/qm5ty98DdgOrgU3A9tZtO3B2W94EXFkjNwLLkxwPnAHsrKr9VXUA2Als7KtuSdLhBrlnkWQt8ELgJmBVVd3fNj0ArGrLq4H7xnbb09pmaz90jC1JJpNMTk9Pz2v9krTU9R4WSX4R+Djwlqr67vi2qiqg5mOcqtpaVRNVNbFy5cr5OKQkqek1LJI8lVFQfLiqPtGaH2yXl2jf+1r7XuCEsd3XtLbZ2iVJA+lzNlSAK4DdVfWnY5uuBQ7OaNoMXDPW/vo2K+o04KF2uep6YEOSFe3G9obWJkkayLIej3068DrgK0lua21/ALwT2JHkAuBe4Ny27TrgLGAKeBg4H6Cq9ie5FLil9bukqvb3WLck6RC9hUVV/S2QWTavn6F/ARfOcqxtwLb5q06S9Hj4BLckqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpU29hkWRbkn1J7hhrOzbJziR3t+8VrT1J3ptkKsntSU4e22dz6393ks191StJml2fZxYfBDYe0nYRcENVrQNuaOsAZwLr2mcLcDmMwgW4GDgVOAW4+GDASJKG01tYVNUXgf2HNG8Ctrfl7cDZY+1X1siNwPIkxwNnADuran9VHQB2cngASZJ6NvQ9i1VVdX9bfgBY1ZZXA/eN9dvT2mZrlyQNaMFucFdVATVfx0uyJclkksnp6en5OqwkieHD4sF2eYn2va+17wVOGOu3prXN1n6YqtpaVRNVNbFy5cp5L1ySlrKhw+Ja4OCMps3ANWPtr2+zok4DHmqXq64HNiRZ0W5sb2htkqQBLevrwEk+CrwUOC7JHkazmt4J7EhyAXAvcG7rfh1wFjAFPAycD1BV+5NcCtzS+l1SVYfeNJck9ay3sKiq18yyaf0MfQu4cJbjbAO2zWNpkqTHySe4JUmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSpyMmLJJsTPK1JFNJLlroeiRpKTkiwiLJUcBfAGcCJwGvSXLSwlYlSUvHEREWwCnAVFXdU1U/Bq4CNi1wTZK0ZBwpYbEauG9sfU9rkyQNIFW10DV0SnIOsLGq/n1bfx1walW9cazPFmBLW30e8LUnOOxxwN8/wWPMh8VQx2KoARZHHdbwM4uhjsVQAyyOOuajhn9aVStn2rDsCR54KHuBE8bW17S2n6qqrcDW+RowyWRVTczX8Y7kOhZDDYulDmtYXHUshhoWSx1913CkXIa6BViX5MQkRwPnAdcucE2StGQcEWcWVfVIkjcC1wNHAduq6s4FLkuSlowjIiwAquo64LoBh5y3S1pP0GKoYzHUAIujDmv4mcVQx2KoARZHHb3WcETc4JYkLawj5Z6FJGkBGRYzWOhXiyTZlmRfkjuGHvuQOk5I8rkkdyW5M8mbF6CGpyW5OcmXWw1/NHQNY7UcleRLST61gDV8M8lXktyWZHIB61ie5OokX02yO8mLBx7/ee3P4ODnu0neMmQNrY7/2P5e3pHko0meNnQNrY43txru7OvPwctQh2ivFvk/wMsZPfx3C/CaqrprwBpeAnwfuLKqfmOocWeo43jg+Kq6NckzgV3A2QP/WQQ4pqq+n+SpwN8Cb66qG4eqYayWtwITwC9V1SuGHr/V8E1goqoWdE5/ku3A/6yq97cZis+oqu8sUC1HMZpKf2pV3TvguKsZ/X08qar+X5IdwHVV9cGhamh1/Aajt1qcAvwY+DTwH6pqaj7H8czicAv+apGq+iKwf8gxZ6nj/qq6tS1/D9jNwE/O18j32+pT22fwf+EkWQP8DvD+ocdebJI8C3gJcAVAVf14oYKiWQ98fcigGLMMeHqSZcAzgP+7ADX8GnBTVT1cVY8AXwBeNd+DGBaH89UiM0iyFnghcNMCjH1UktuAfcDOqhq8BuDPgN8H/nEBxh5XwGeS7GpvLVgIJwLTwAfaZbn3JzlmgWqB0XNXHx160KraC/wx8C3gfuChqvrM0HUAdwD/MsmzkzwDOItHP8Q8LwwLdUryi8DHgbdU1XeHHr+qflJVL2D05P4p7bR7MEleAeyrql1DjjuL36qqkxm9gfnCdslyaMuAk4HLq+qFwA+ABfm1Ae0S2CuBjy3A2CsYXXU4EXgOcEyS1w5dR1XtBt4FfIbRJajbgJ/M9ziGxeE6Xy2ylLT7BB8HPlxVn1jIWtqljs8BGwce+nTgle1+wVXAy5L81cA1AD/91yxVtQ/4JKPLpkPbA+wZO8O7mlF4LIQzgVur6sEFGPtfA9+oqumq+gfgE8BvLkAdVNUVVfWiqnoJcIDRfdd5ZVgczleLNO3m8hXA7qr60wWqYWWS5W356YwmHnx1yBqq6u1Vtaaq1jL6+/DZqhr8X5BJjmkTDWiXfTYwugQxqKp6ALgvyfNa03pgsEkPh3gNC3AJqvkWcFqSZ7T/VtYzuq83uCS/3L5/hdH9io/M9xhHzBPcQ1kMrxZJ8lHgpcBxSfYAF1fVFUPW0JwOvA74SrtnAPAH7Wn6oRwPbG8zXp4C7KiqBZu6usBWAZ8c/X+JZcBHqurTC1TLm4APt39Q3QOcP3QBLTBfDrxh6LEBquqmJFcDtwKPAF9i4Z7k/niSZwP/AFzYx4QDp85Kkjp5GUqS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUqf/D/lTeRWqSG9oAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.countplot(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlWna8LC6N7j"
      },
      "source": [
        "There are similar counts for each digit. This is good as the model will have enough images for each class to train the features for each class. There is no need to downsample or upweigh."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdpy9Xw06N7j"
      },
      "source": [
        "## 2.2 Check for NaN Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmlXkZxo6N7k",
        "outputId": "56ff37a6-8176-4e25-b62f-c2684b8b00bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "np.isnan(x_train).any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgQPIArD6N7k",
        "outputId": "f9992ee0-e7ef-4777-fbc4-7797807db22d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "np.isnan(x_test).any()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Xye138C6N7l"
      },
      "source": [
        "There are no NaN values in our dataset. There is no need to preprocess the data to deal with Nan's."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHQ4yLj_6N7l"
      },
      "source": [
        "## 2.3 Normalization and Reshaping\n",
        "\n",
        "Since the values in our ```x_train``` dataset are 28x28 images, our input shape must be specified so that our model will know what is being inputed.\n",
        "\n",
        "The first convolution layer expects a single 60000x28x28x1 tensor instead of 60000 28x28x1 tensors.\n",
        "\n",
        "Models generally run better on normalized values. The best way to normalize the data depends on each individual dataset. For the MNIST dataset, we want each value to be between 0.0 and 1.0. As all values originally fall under the 0.0-255.0 range, divide by 255.0.\n",
        "\n",
        "Run the following cell to define the ```input_shape``` and to normalize and reshape the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jV3cgXgP6N7m"
      },
      "outputs": [],
      "source": [
        "input_shape = (28, 28, 1)\n",
        "\n",
        "x_train=x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "x_train=x_train / 255.0\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
        "x_test=x_test/255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOOTjHLy6N7m"
      },
      "source": [
        "## 2.4 Label Encoding\n",
        "\n",
        "The labels for the training and the testing dataset are currently categorical and is not continuous. To include categorical dataset in our model, our labels should be converted to one-hot encodings.\n",
        "\n",
        "For example, ```2``` becomes ```[0,0,1,0,0,0,0,0,0,0]``` and ```7``` becomes ```[0,0,0,0,0,0,0,1,0,0]```.\n",
        "\n",
        "Run the following cell to transform the labels into one-hot encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "N60OSnQM6N7n"
      },
      "outputs": [],
      "source": [
        "y_train = tf.one_hot(y_train.astype(np.int32), depth=10)\n",
        "y_test = tf.one_hot(y_test.astype(np.int32), depth=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_VT_27H6N7n"
      },
      "source": [
        "## 2.5 Visualize Data\n",
        "\n",
        "Run the following cell to visualize an image in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "0dMzhGd16N7o",
        "outputId": "58a8ab58-10c8-4834-f752-c9411863a659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0. 0. 0. 0. 0. 1. 0. 0. 0. 0.], shape=(10,), dtype=float32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(x_train[100][:,:,0])\n",
        "print(y_train[100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDAQvbMv6N7o"
      },
      "source": [
        "The image is an image of a handwritten ```5```. The one-hot encoding holds the value of ```5```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkI6R7p_6N7p"
      },
      "source": [
        "# 3. CNN\n",
        "\n",
        "In this module, we will build our CNN model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fwf3fx-s6N7p"
      },
      "source": [
        "## 3.1 Define the Model\n",
        "\n",
        "Run the following cell to define ```batch_size```, ```num_classes```, and ```epochs```. Try changing the values and test how different values affect the accuracy of the CNN model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3BSgPmfd6N7p"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDPl3f8c6N7q"
      },
      "source": [
        "Run the following cell to build the model. The model contains various layers stacked on top of each other. The output of one layer feeds into the input of the next layer.\n",
        "\n",
        "Conv2D layers are convolutions. Each filter (32 in the first two convolution layers and 64 in the next two convolution layers) transforms a part of the image (5x5 for the first two Conv2D layers and 3x3 for the next two Conv2D layers). The transformation is applied on the whole image.\n",
        "\n",
        "MaxPool2D is a downsampling filter. It reduces a 2x2 matrix of the image to a single pixel with the maximum value of the 2x2 matrix. The filter aims to conserve the main features of the image while reducing the size.\n",
        "\n",
        "Dropout is a regularization layer. In our model, 25% of the nodes in the layer are randomly ignores, allowing the network to learn different features. This prevents overfitting.\n",
        "\n",
        "```relu``` is the rectifier, and it is used to find nonlinearity in the data. It works by returning the input value if the input value >= 0. If the input is negative, it returns 0.\n",
        "\n",
        "Flatten converts the tensors into a 1D vector.\n",
        "\n",
        "The Dense layers are an artificial neural network (ANN). The last layer returns the probability that an image is in each class (one for each digit).\n",
        "\n",
        "As this model aims to categorize the images, we will use a ```categorical_crossentropy``` loss function. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OLN-jkxg6N7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d1ede06-e0a7-48fe-9308-038d55fb6787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 28, 28, 320)       8320      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 320)       2560320   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 320)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 320)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 62720)             0         \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 62720)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                627210    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,195,850\n",
            "Trainable params: 3,195,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "\n",
        "numberOfHiddenLayers = 2  #default = 5, if 0 then useSVM=True\n",
        "generateLargeNetworkUntrained = True\n",
        "addSkipLayers = False\n",
        "if(numberOfHiddenLayers > 1):\n",
        "  addSkipLayers = False #True  #optional\n",
        "\n",
        "if(generateLargeNetworkUntrained):\n",
        "  generateNetworkUntrained = True\n",
        "  largeNetworkRatio = 10  #100\n",
        "  generateLargeNetworkExpansion = False\n",
        "  if(generateLargeNetworkExpansion):\n",
        "    generateLargeNetworkRatioExponential = False\n",
        "else:\n",
        "  generateNetworkUntrained = False\n",
        "  generateLargeNetworkRatio = False\n",
        "\n",
        "def getLayerRatio(layerIndex):\n",
        "  layerRatio = 1\n",
        "  if(generateLargeNetworkUntrained):\n",
        "    if(generateLargeNetworkExpansion):\n",
        "      if(generateLargeNetworkRatioExponential):\n",
        "        layerRatio = largeNetworkRatio**layerIndex\n",
        "      else:\n",
        "        layerRatio = largeNetworkRatio * layerIndex\n",
        "    else:\n",
        "      layerRatio = largeNetworkRatio\n",
        "  else:\n",
        "    layerRatio = 1\n",
        "  return int(layerRatio)\n",
        "\n",
        "x = tf.keras.layers.Input(shape=input_shape)\n",
        "hLast = x\n",
        "if(numberOfHiddenLayers >= 1):\n",
        "  layerRatio = getLayerRatio(1)\n",
        "  h1 = tf.keras.layers.Conv2D(32*layerRatio, (5,5), padding='same', activation='relu')(x)\n",
        "  hLast = h1\n",
        "if(numberOfHiddenLayers >= 2):\n",
        "  layerRatio = getLayerRatio(2)\n",
        "  h2 = tf.keras.layers.Conv2D(32*layerRatio, (5,5), padding='same', activation='relu')(h1)\n",
        "  h2 = tf.keras.layers.MaxPool2D()(h2)\n",
        "  h2 = tf.keras.layers.Dropout(0.25)(h2)\n",
        "  hLast = h2\n",
        "if(numberOfHiddenLayers >= 3):\n",
        "  layerRatio = getLayerRatio(3)\n",
        "  h3 = tf.keras.layers.Conv2D(32*layerRatio, (3,3), padding='same', activation='relu')(h2)\n",
        "  hLast = h3\n",
        "if(numberOfHiddenLayers >= 4):\n",
        "  layerRatio = getLayerRatio(4)\n",
        "  h4 = tf.keras.layers.Conv2D(32*layerRatio, (3,3), padding='same', activation='relu')(h3)\n",
        "  h4 = tf.keras.layers.MaxPool2D(strides=(2,2))(h4)\n",
        "  h4 = tf.keras.layers.Flatten()(h4)\n",
        "  hLast = h4\n",
        "if(numberOfHiddenLayers >= 5):\n",
        "  layerRatio = getLayerRatio(5)\n",
        "  h5 = tf.keras.layers.Dense(128*layerRatio, activation='relu')(h4)\n",
        "  h5 = tf.keras.layers.Dropout(0.5)(h5)\n",
        "  hLast = h5\n",
        "if(addSkipLayers):\n",
        "  mList = []\n",
        "  if(numberOfHiddenLayers >= 1):\n",
        "    m1 = tf.keras.layers.Flatten()(h1)\n",
        "    mList.append(m1)\n",
        "  if(numberOfHiddenLayers >= 2):\n",
        "    m2 = tf.keras.layers.Flatten()(h2)\n",
        "    mList.append(m2)\n",
        "  if(numberOfHiddenLayers >= 3):\n",
        "    m3 = tf.keras.layers.Flatten()(h3)\n",
        "    mList.append(m3)\n",
        "  if(numberOfHiddenLayers >= 4):\n",
        "    m4 = tf.keras.layers.Flatten()(h4)\n",
        "    mList.append(m4)\n",
        "  if(numberOfHiddenLayers >= 5):\n",
        "    m5 = h5\n",
        "    mList.append(m5)\n",
        "  hLast = tf.keras.layers.concatenate(mList)\n",
        "hLast = tf.keras.layers.Flatten()(hLast)  #flatten hLast if necessary (ie numberOfHiddenLayers <4)\n",
        "if(generateNetworkUntrained):\n",
        "  hLast = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stop_gradient(x))(hLast)\n",
        "y = tf.keras.layers.Dense(num_classes, activation='softmax')(hLast)\n",
        "model = tf.keras.Model(x, y)\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(epsilon=1e-08), loss='categorical_crossentropy', metrics=['acc'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDeOzJFI6N7r"
      },
      "source": [
        "## 3.2 Fit the Training Data\n",
        "\n",
        "The next step is to fit our training data. If we achieve a certain level of accuracy, it may not be necessary to continue training the model, especially if time and resources are limited.\n",
        "\n",
        "The following cell defines a CallBack so that if 99.5% accuracy is achieved, the model stops training. The model is not likely to stop prematurely if only 5 epochs are specified. Try it out with more epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KM1t_AIX6N7r"
      },
      "outputs": [],
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.995):\n",
        "      print(\"\\nReached 99.5% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3-Edk1Q6N7s"
      },
      "source": [
        "Testing the model on a validation dataset prevents overfitting of the data. We specified a 10% validation and 90% training split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9ocCw_T6N7s",
        "outputId": "f01278f9-6108-47ab-f698-23ef97c0c991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "844/844 [==============================] - 2871s 3s/step - loss: 0.2968 - acc: 0.9210 - val_loss: 0.1285 - val_acc: 0.9668\n",
            "Epoch 2/5\n",
            "844/844 [==============================] - 2891s 3s/step - loss: 0.1437 - acc: 0.9586 - val_loss: 0.0958 - val_acc: 0.9740\n",
            "Epoch 3/5\n",
            "844/844 [==============================] - 2905s 3s/step - loss: 0.1102 - acc: 0.9692 - val_loss: 0.0797 - val_acc: 0.9797\n",
            "Epoch 4/5\n",
            "844/844 [==============================] - 2887s 3s/step - loss: 0.0915 - acc: 0.9741 - val_loss: 0.0724 - val_acc: 0.9810\n",
            "Epoch 5/5\n",
            "844/844 [==============================] - 2856s 3s/step - loss: 0.0788 - acc: 0.9775 - val_loss: 0.0690 - val_acc: 0.9818\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[callbacks])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr34Iqnn6N7s"
      },
      "source": [
        "# 4. Evaluate the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqvc6ES76N7s"
      },
      "source": [
        "## 4.1 Loss and Accuracy Curves\n",
        "\n",
        "Run the following cell to evaluate the loss and accuracy of our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BuCQbNgW6N7s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "4d8d386f-399b-4483-b44e-877f04bb9a2d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig, ax = plt.subplots(2,1)\n",
        "ax[0].plot(history.history['loss'], color='b', label=\"Training Loss\")\n",
        "ax[0].plot(history.history['val_loss'], color='r', label=\"Validation Loss\",axes =ax[0])\n",
        "legend = ax[0].legend(loc='best', shadow=True)\n",
        "\n",
        "ax[1].plot(history.history['acc'], color='b', label=\"Training Accuracy\")\n",
        "ax[1].plot(history.history['val_acc'], color='r',label=\"Validation Accuracy\")\n",
        "legend = ax[1].legend(loc='best', shadow=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5ChJfLQ6N7u"
      },
      "source": [
        "The accuracy increases over time and the loss decreases over time. However, the accuracy of our validation set seems to slightly decrease towards the end even thought our training accuracy increased. Running the model for more epochs might cause our model to be susceptible to overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6JiUyTe6N7u"
      },
      "source": [
        "## 4.2 Predict Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7Jz4oEW06N7u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da4388fd-9240-4368-a271-1f5d1c2712ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 474s 2s/step - loss: 0.0810 - acc: 0.9758\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dozTBo5G6N7v"
      },
      "source": [
        "Our model runs pretty well, with an accuracy of 99.3% on our testing data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg6DZgcv6N7v"
      },
      "source": [
        "## 4.3 Confusion Matrix\n",
        "\n",
        "Run the following cell to compute our confusion matrix using TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2EUqmdvq6N7v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "761cdc3a-770b-414b-dc74-fc64af46c177"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-3c5a4c131f28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predict the values from the testing dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Convert predictions classes to one hot vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY_pred_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Convert testing observations to one hot vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1980\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1982\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1983\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1984\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Predict the values from the testing dataset\n",
        "Y_pred = model.predict(x_test)\n",
        "# Convert predictions classes to one hot vectors \n",
        "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
        "# Convert testing observations to one hot vectors\n",
        "Y_true = np.argmax(y_test,axis = 1)\n",
        "# compute the confusion matrix\n",
        "confusion_mtx = tf.math.confusion_matrix(Y_true, Y_pred_classes) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZjDurLZ6N7v"
      },
      "source": [
        "Run the following cell to plot the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ytj2AMX6N7w"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(confusion_mtx, annot=True, fmt='g')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7AQaxdS6N7w"
      },
      "source": [
        "There seems to be a slightly higher confusion between (0,6) and (4,9). This is reasonable as 0's and 6's look similar with their loops and 4's and 9's can be mistaken when the 4's are more rounded and 9's are more angular."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MNISTlargeUntrainedNetCNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}