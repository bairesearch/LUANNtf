{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10largeUntrainedNetCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Adapted from https://keras.io/zh/examples/cifar10_cnn_tfaugment2d/\n",
        "\n",
        "numberOfHiddenLayers = 2  #default = 5, if 0 then useSVM=True\n",
        "generateLargeNetworkUntrained = True\n",
        "#addSkipLayers = False  #skip layers not supported by keras model.add definition format\n",
        "\n",
        "if(generateLargeNetworkUntrained):\n",
        "  generateNetworkUntrained = True\n",
        "  largeNetworkRatio = 10\n",
        "  generateLargeNetworkExpansion = False\n",
        "  if(generateLargeNetworkExpansion):\n",
        "    generateLargeNetworkRatioExponential = True\n",
        "else:\n",
        "  generateNetworkUntrained = False\n",
        "  generateLargeNetworkRatio = False\n",
        "\n",
        "def getLayerRatio(layerIndex):\n",
        "  layerRatio = 1\n",
        "  if(generateLargeNetworkUntrained):\n",
        "    if(generateLargeNetworkExpansion):\n",
        "      if(generateLargeNetworkRatioExponential):\n",
        "        layerRatio = largeNetworkRatio**layerIndex\n",
        "      else:\n",
        "        layerRatio = largeNetworkRatio * layerIndex\n",
        "    else:\n",
        "      layerRatio = largeNetworkRatio\n",
        "  else:\n",
        "    layerRatio = 1\n",
        "  return int(layerRatio)\n"
      ],
      "metadata": {
        "id": "oEK0GMrRI6mp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEHJ0qXiDd0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b46727-2e19-4d08-bc00-a4d621ab8e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "170508288/170498071 [==============================] - 6s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "input_shape =  (32, 32, 3)\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "1563/1563 [==============================] - 1211s 775ms/step - loss: 1.8666 - accuracy: 0.3546 - val_loss: 1.7109 - val_accuracy: 0.4174\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 1213s 776ms/step - loss: 1.6603 - accuracy: 0.4331 - val_loss: 1.6126 - val_accuracy: 0.4504\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 1212s 775ms/step - loss: 1.5828 - accuracy: 0.4585 - val_loss: 1.5554 - val_accuracy: 0.4652\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 1210s 774ms/step - loss: 1.5293 - accuracy: 0.4787 - val_loss: 1.5167 - val_accuracy: 0.4818\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 1211s 775ms/step - loss: 1.4910 - accuracy: 0.4917 - val_loss: 1.4976 - val_accuracy: 0.4715\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 1211s 775ms/step - loss: 1.4588 - accuracy: 0.5042 - val_loss: 1.4599 - val_accuracy: 0.4990\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 1212s 775ms/step - loss: 1.4319 - accuracy: 0.5141 - val_loss: 1.4368 - val_accuracy: 0.5118\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 1213s 776ms/step - loss: 1.4078 - accuracy: 0.5236 - val_loss: 1.4161 - val_accuracy: 0.5188\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 1212s 776ms/step - loss: 1.3870 - accuracy: 0.5319 - val_loss: 1.4103 - val_accuracy: 0.5129\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 1213s 776ms/step - loss: 1.3692 - accuracy: 0.5362 - val_loss: 1.3799 - val_accuracy: 0.5357\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 1218s 780ms/step - loss: 1.3522 - accuracy: 0.5427 - val_loss: 1.3730 - val_accuracy: 0.5321\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 1220s 781ms/step - loss: 1.3363 - accuracy: 0.5501 - val_loss: 1.3664 - val_accuracy: 0.5305\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 1217s 779ms/step - loss: 1.3222 - accuracy: 0.5542 - val_loss: 1.3489 - val_accuracy: 0.5412\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 1218s 780ms/step - loss: 1.3088 - accuracy: 0.5590 - val_loss: 1.3346 - val_accuracy: 0.5471\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 1219s 780ms/step - loss: 1.2963 - accuracy: 0.5636 - val_loss: 1.3330 - val_accuracy: 0.5502\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 1220s 781ms/step - loss: 1.2853 - accuracy: 0.5701 - val_loss: 1.3277 - val_accuracy: 0.5492\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 1221s 782ms/step - loss: 1.2750 - accuracy: 0.5707 - val_loss: 1.3107 - val_accuracy: 0.5559\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 1225s 784ms/step - loss: 1.2644 - accuracy: 0.5750 - val_loss: 1.3030 - val_accuracy: 0.5564\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 1225s 784ms/step - loss: 1.2539 - accuracy: 0.5791 - val_loss: 1.3033 - val_accuracy: 0.5585\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 1222s 782ms/step - loss: 1.2461 - accuracy: 0.5828 - val_loss: 1.2869 - val_accuracy: 0.5627\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 1222s 782ms/step - loss: 1.2363 - accuracy: 0.5866 - val_loss: 1.2925 - val_accuracy: 0.5566\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 1220s 781ms/step - loss: 1.2269 - accuracy: 0.5907 - val_loss: 1.2756 - val_accuracy: 0.5672\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 1221s 781ms/step - loss: 1.2204 - accuracy: 0.5912 - val_loss: 1.2773 - val_accuracy: 0.5672\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 1221s 781ms/step - loss: 1.2113 - accuracy: 0.5936 - val_loss: 1.2582 - val_accuracy: 0.5742\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 1221s 782ms/step - loss: 1.2048 - accuracy: 0.5975 - val_loss: 1.2693 - val_accuracy: 0.5659\n",
            "Epoch 26/100\n",
            "1563/1563 [==============================] - 1220s 781ms/step - loss: 1.1967 - accuracy: 0.6006 - val_loss: 1.2528 - val_accuracy: 0.5778\n",
            "Epoch 27/100\n",
            "1563/1563 [==============================] - 1220s 781ms/step - loss: 1.1901 - accuracy: 0.6041 - val_loss: 1.2595 - val_accuracy: 0.5753\n",
            "Epoch 28/100\n",
            "1563/1563 [==============================] - 1219s 780ms/step - loss: 1.1838 - accuracy: 0.6044 - val_loss: 1.2644 - val_accuracy: 0.5646\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - 1221s 782ms/step - loss: 1.1776 - accuracy: 0.6077 - val_loss: 1.2481 - val_accuracy: 0.5712\n",
            "Epoch 30/100\n",
            "1563/1563 [==============================] - 1221s 782ms/step - loss: 1.1716 - accuracy: 0.6086 - val_loss: 1.2421 - val_accuracy: 0.5778\n",
            "Epoch 31/100\n",
            "1563/1563 [==============================] - 1221s 781ms/step - loss: 1.1652 - accuracy: 0.6129 - val_loss: 1.2440 - val_accuracy: 0.5754\n",
            "Epoch 32/100\n",
            "1563/1563 [==============================] - 1222s 782ms/step - loss: 1.1599 - accuracy: 0.6123 - val_loss: 1.2441 - val_accuracy: 0.5746\n",
            "Epoch 33/100\n",
            "1563/1563 [==============================] - 1223s 783ms/step - loss: 1.1544 - accuracy: 0.6147 - val_loss: 1.2389 - val_accuracy: 0.5768\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - 1225s 784ms/step - loss: 1.1479 - accuracy: 0.6173 - val_loss: 1.2145 - val_accuracy: 0.5914\n",
            "Epoch 35/100\n",
            "1563/1563 [==============================] - 1229s 786ms/step - loss: 1.1430 - accuracy: 0.6200 - val_loss: 1.2194 - val_accuracy: 0.5924\n",
            "Epoch 36/100\n",
            " 907/1563 [================>.............] - ETA: 7:12 - loss: 1.1423 - accuracy: 0.6205"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, Lambda, MaxPooling2D\n",
        "from keras import backend as K\n",
        "import os\n",
        "\n",
        "if K.backend() != 'tensorflow':\n",
        "    raise RuntimeError('This example can only run with the '\n",
        "                       'TensorFlow backend, '\n",
        "                       'because it requires TF-native augmentation APIs')\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "num_predictions = 20\n",
        "save_dir = '/tmp/saved_models'\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "input_shape = (x_train.shape[1], x_train.shape[2], x_train.shape[3])\n",
        "print(\"input_shape = \", input_shape)\n",
        "\n",
        "model = Sequential()\n",
        "#model.add(Input(shape=input_shape))\n",
        "if(numberOfHiddenLayers >= 1):\n",
        "  layerRatio = getLayerRatio(1)\n",
        "  model.add(Conv2D(32*layerRatio, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "if(numberOfHiddenLayers >= 2):\n",
        "  layerRatio = getLayerRatio(2)\n",
        "  model.add(Conv2D(32*layerRatio, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "if(numberOfHiddenLayers >= 3):\n",
        "  layerRatio = getLayerRatio(3)\n",
        "  model.add(Conv2D(64*layerRatio, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "if(numberOfHiddenLayers >= 4):\n",
        "  layerRatio = getLayerRatio(4)\n",
        "  model.add(Conv2D(64*layerRatio, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "if(numberOfHiddenLayers >= 5):\n",
        "  layerRatio = getLayerRatio(5)\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512*generateLargeNetworkRatio))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())  #flatten hLast if necessary (ie numberOfHiddenLayers <4)\n",
        "if(generateLargeNetworkUntrained):\n",
        "  model.add(Lambda(lambda x: tf.keras.backend.stop_gradient(x)))\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          shuffle=True)\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# Save model and weights\n",
        "#if not os.path.isdir(save_dir):\n",
        "#    os.makedirs(save_dir)\n",
        "#model_path = os.path.join(save_dir, model_name)\n",
        "#model.save(model_path)\n",
        "#print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ]
    }
  ]
}